{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "63054cfc-2ee7-4425-b8e0-f3edaf54d342",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PySpark executors will use /usr/lib/anaconda-wmf/bin/python3.\n",
      "22/08/08 19:18:47 WARN SparkConf: Note that spark.local.dir will be overridden by the value set by the cluster manager (via SPARK_LOCAL_DIRS in mesos/standalone/kubernetes and LOCAL_DIRS in YARN).\n",
      "22/08/08 19:18:47 WARN Utils: Service 'sparkDriver' could not bind on port 12000. Attempting port 12001.\n",
      "22/08/08 19:18:47 WARN Utils: Service 'sparkDriver' could not bind on port 12001. Attempting port 12002.\n",
      "22/08/08 19:18:47 WARN Utils: Service 'sparkDriver' could not bind on port 12002. Attempting port 12003.\n",
      "22/08/08 19:18:47 WARN Utils: Service 'sparkDriver' could not bind on port 12003. Attempting port 12004.\n",
      "22/08/08 19:18:47 WARN Utils: Service 'sparkDriver' could not bind on port 12004. Attempting port 12005.\n",
      "22/08/08 19:18:47 WARN Utils: Service 'sparkDriver' could not bind on port 12005. Attempting port 12006.\n",
      "22/08/08 19:18:47 WARN Utils: Service 'sparkDriver' could not bind on port 12006. Attempting port 12007.\n",
      "22/08/08 19:18:47 WARN Utils: Service 'sparkDriver' could not bind on port 12007. Attempting port 12008.\n",
      "22/08/08 19:18:47 WARN Utils: Service 'sparkDriver' could not bind on port 12008. Attempting port 12009.\n",
      "22/08/08 19:18:47 WARN Utils: Service 'sparkDriver' could not bind on port 12009. Attempting port 12010.\n",
      "22/08/08 19:18:47 WARN Utils: Service 'sparkDriver' could not bind on port 12010. Attempting port 12011.\n",
      "22/08/08 19:18:47 WARN Utils: Service 'sparkDriver' could not bind on port 12011. Attempting port 12012.\n",
      "22/08/08 19:18:47 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.\n",
      "22/08/08 19:18:47 WARN Utils: Service 'SparkUI' could not bind on port 4041. Attempting port 4042.\n",
      "22/08/08 19:18:47 WARN Utils: Service 'SparkUI' could not bind on port 4042. Attempting port 4043.\n",
      "22/08/08 19:18:47 WARN Utils: Service 'SparkUI' could not bind on port 4043. Attempting port 4044.\n",
      "22/08/08 19:18:47 WARN Utils: Service 'SparkUI' could not bind on port 4044. Attempting port 4045.\n",
      "22/08/08 19:18:47 WARN Utils: Service 'SparkUI' could not bind on port 4045. Attempting port 4046.\n",
      "22/08/08 19:18:47 WARN Utils: Service 'SparkUI' could not bind on port 4046. Attempting port 4047.\n",
      "22/08/08 19:18:47 WARN Utils: Service 'SparkUI' could not bind on port 4047. Attempting port 4048.\n",
      "22/08/08 19:18:47 WARN Utils: Service 'SparkUI' could not bind on port 4048. Attempting port 4049.\n",
      "22/08/08 19:18:47 WARN Utils: Service 'SparkUI' could not bind on port 4049. Attempting port 4050.\n",
      "22/08/08 19:18:47 WARN Utils: Service 'SparkUI' could not bind on port 4050. Attempting port 4051.\n",
      "22/08/08 19:18:47 WARN Utils: Service 'SparkUI' could not bind on port 4051. Attempting port 4052.\n",
      "22/08/08 19:18:54 WARN Utils: Service 'org.apache.spark.network.netty.NettyBlockTransferService' could not bind on port 13000. Attempting port 13001.\n",
      "22/08/08 19:18:54 WARN Utils: Service 'org.apache.spark.network.netty.NettyBlockTransferService' could not bind on port 13001. Attempting port 13002.\n",
      "22/08/08 19:18:54 WARN Utils: Service 'org.apache.spark.network.netty.NettyBlockTransferService' could not bind on port 13002. Attempting port 13003.\n",
      "22/08/08 19:18:54 WARN Utils: Service 'org.apache.spark.network.netty.NettyBlockTransferService' could not bind on port 13003. Attempting port 13004.\n",
      "22/08/08 19:18:54 WARN Utils: Service 'org.apache.spark.network.netty.NettyBlockTransferService' could not bind on port 13004. Attempting port 13005.\n",
      "22/08/08 19:18:54 WARN Utils: Service 'org.apache.spark.network.netty.NettyBlockTransferService' could not bind on port 13005. Attempting port 13006.\n",
      "22/08/08 19:18:54 WARN Utils: Service 'org.apache.spark.network.netty.NettyBlockTransferService' could not bind on port 13006. Attempting port 13007.\n",
      "22/08/08 19:18:54 WARN Utils: Service 'org.apache.spark.network.netty.NettyBlockTransferService' could not bind on port 13007. Attempting port 13008.\n",
      "22/08/08 19:18:54 WARN Utils: Service 'org.apache.spark.network.netty.NettyBlockTransferService' could not bind on port 13008. Attempting port 13009.\n",
      "22/08/08 19:18:54 WARN Utils: Service 'org.apache.spark.network.netty.NettyBlockTransferService' could not bind on port 13009. Attempting port 13010.\n",
      "22/08/08 19:18:54 WARN Utils: Service 'org.apache.spark.network.netty.NettyBlockTransferService' could not bind on port 13010. Attempting port 13011.\n",
      "22/08/08 19:18:54 WARN Utils: Service 'org.apache.spark.network.netty.NettyBlockTransferService' could not bind on port 13011. Attempting port 13012.\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python3\n",
    "import wmfdata as wmf\n",
    "import pandas as pd\n",
    "import matplotlib\n",
    "\n",
    "matplotlib.style.use('ggplot')\n",
    "\n",
    "spark = wmf.spark.get_custom_session(\n",
    "    master=\"yarn\",\n",
    "    spark_config={\n",
    "        \"spark.driver.memory\": \"16g\",\n",
    "        \"spark.dynamicAllocation.maxExecutors\": 128,\n",
    "        \"spark.executor.memory\": \"16g\",\n",
    "        \"spark.executor.cores\": 4,\n",
    "        \"spark.sql.shuffle.partitions\": 512\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7b17f935-8dce-41f0-a2e8-29025e076fe3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PySpark executors will use /usr/lib/anaconda-wmf/bin/python3.\n",
      "22/08/07 20:27:05 WARN SharedInMemoryCache: Evicting cached table partition metadata from memory due to size constraints (spark.sql.hive.filesourcePartitionFileCacheSize = 262144000 bytes). This may impact query planning performance.\n",
      "22/08/07 20:27:18 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "22/08/07 20:27:18 WARN Utils: Truncated the string representation of a plan since it was too large. This behavior can be adjusted by setting 'spark.debug.maxToStringFields' in SparkEnv.conf.\n",
      "                                                                                ]]5375]\r"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>month</th>\n",
       "      <th>year</th>\n",
       "      <th>num_pageviews</th>\n",
       "      <th>num_new_accounts</th>\n",
       "      <th>num_articles</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7</td>\n",
       "      <td>2018</td>\n",
       "      <td>6356664047</td>\n",
       "      <td>56756</td>\n",
       "      <td>25803728</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8</td>\n",
       "      <td>2018</td>\n",
       "      <td>6289665286</td>\n",
       "      <td>59618</td>\n",
       "      <td>26099767</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7</td>\n",
       "      <td>2020</td>\n",
       "      <td>6478241839</td>\n",
       "      <td>56579</td>\n",
       "      <td>30524897</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>12</td>\n",
       "      <td>2020</td>\n",
       "      <td>6616498273</td>\n",
       "      <td>51393</td>\n",
       "      <td>31246667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>2018</td>\n",
       "      <td>6030892434</td>\n",
       "      <td>62961</td>\n",
       "      <td>24856599</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>8</td>\n",
       "      <td>2019</td>\n",
       "      <td>6206375530</td>\n",
       "      <td>55260</td>\n",
       "      <td>28226775</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>3</td>\n",
       "      <td>2017</td>\n",
       "      <td>6615775728</td>\n",
       "      <td>78009</td>\n",
       "      <td>22897713</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>9</td>\n",
       "      <td>2016</td>\n",
       "      <td>5937693760</td>\n",
       "      <td>63243</td>\n",
       "      <td>22217550</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>1</td>\n",
       "      <td>2022</td>\n",
       "      <td>6365364819</td>\n",
       "      <td>52232</td>\n",
       "      <td>33279155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>8</td>\n",
       "      <td>2021</td>\n",
       "      <td>6146736497</td>\n",
       "      <td>46501</td>\n",
       "      <td>32424097</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>88 rows Ã— 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    month  year  num_pageviews  num_new_accounts  num_articles\n",
       "0       7  2018     6356664047             56756      25803728\n",
       "1       8  2018     6289665286             59618      26099767\n",
       "2       7  2020     6478241839             56579      30524897\n",
       "3      12  2020     6616498273             51393      31246667\n",
       "4       2  2018     6030892434             62961      24856599\n",
       "..    ...   ...            ...               ...           ...\n",
       "83      8  2019     6206375530             55260      28226775\n",
       "84      3  2017     6615775728             78009      22897713\n",
       "85      9  2016     5937693760             63243      22217550\n",
       "86      1  2022     6365364819             52232      33279155\n",
       "87      8  2021     6146736497             46501      32424097\n",
       "\n",
       "[88 rows x 5 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = \"\"\"\n",
    "WITH pageviews AS (\n",
    "SELECT month, year, COUNT(*) AS num_pageviews\n",
    "FROM wmf.pageview_hourly\n",
    "WHERE agent_type = 'user'\n",
    "AND project = 'en.wikipedia'\n",
    "GROUP BY month, year\n",
    "), \n",
    "\n",
    "new_accounts AS (\n",
    "SELECT\n",
    "    cast(substr(user_first_edit_timestamp,1,4) as int) as year, \n",
    "    cast(substr(user_first_edit_timestamp,6,2) as int) as month,\n",
    "    COUNT(*) AS num_new_accounts\n",
    "FROM wmf.mediawiki_user_history \n",
    "WHERE snapshot = '2022-07'\n",
    "AND wiki_db = 'enwiki'\n",
    "AND array_contains(user_groups,'bot') = FALSE\n",
    "AND user_first_edit_timestamp IS NOT NULL\n",
    "GROUP BY\n",
    "    cast(substr(user_first_edit_timestamp,1,4) as int),\n",
    "    cast(substr(user_first_edit_timestamp,6,2) as int)\n",
    "),\n",
    "    \n",
    "articles_created AS (\n",
    "SELECT\n",
    "    cast(substr(start_timestamp ,1,4) as int) as year, \n",
    "    cast(substr(start_timestamp,6,2) as int) as month,\n",
    "    COUNT(*) AS num_articles_created\n",
    "FROM wmf.mediawiki_page_history \n",
    "WHERE snapshot = '2022-07'\n",
    "AND page_namespace = 1\n",
    "GROUP BY\n",
    "    cast(substr(start_timestamp,1,4) as int),\n",
    "    cast(substr(start_timestamp,6,2) as int)\n",
    "),\n",
    "\n",
    "articles_deleted AS (\n",
    "SELECT\n",
    "    cast(substr(end_timestamp ,1,4) as int) as year, \n",
    "    cast(substr(end_timestamp,6,2) as int) as month,\n",
    "    COUNT(*) AS num_articles_deleted\n",
    "FROM wmf.mediawiki_page_history \n",
    "WHERE snapshot = '2022-07'\n",
    "AND page_namespace = 1\n",
    "GROUP BY\n",
    "    cast(substr(end_timestamp,1,4) as int),\n",
    "    cast(substr(end_timestamp,6,2) as int)\n",
    "),\n",
    "\n",
    "num_articles AS (\n",
    "SELECT\n",
    "    articles_created.month,\n",
    "    articles_created.year,\n",
    "    COALESCE(articles_deleted.num_articles_deleted,0) AS articles_deleted,\n",
    "    articles_created.num_articles_created,\n",
    "    articles_created.num_articles_created-COALESCE(articles_deleted.num_articles_deleted,0) AS article_diff,\n",
    "    SUM(articles_created.num_articles_created-COALESCE(articles_deleted.num_articles_deleted,0)) OVER (ORDER BY articles_created.year, articles_created.month) AS num_articles \n",
    "FROM articles_created\n",
    "LEFT JOIN articles_deleted\n",
    "ON (articles_created.month = articles_deleted.month AND articles_created.year = articles_deleted.year)\n",
    "WHERE articles_created.month IS NOT NULL\n",
    "AND articles_created.year IS NOT NULL\n",
    ")\n",
    "\n",
    "SELECT pageviews.month, pageviews.year, pageviews.num_pageviews, new_accounts.num_new_accounts, num_articles.num_articles\n",
    "FROM pageviews\n",
    "INNER JOIN new_accounts\n",
    "ON pageviews.year = new_accounts.year AND pageviews.month = new_accounts.month\n",
    "INNER JOIN num_articles\n",
    "ON pageviews.year = num_articles.year AND pageviews.month = num_articles.month\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "df = wmf.spark.run(query)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b9f9bb97-2e7d-4947-b3f9-65c50d47d081",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_df = df.copy()\n",
    "min_year = result_df['year'].min()\n",
    "result_df['wiki_age'] = result_df['year'].subtract(min_year).multiply(12).add(result_df['month'])\n",
    "result_df = result_df.sort_values(['year','month'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3cb838fa-3c42-43b5-a6d4-254e6394ec55",
   "metadata": {},
   "outputs": [],
   "source": [
    "FILEPATH = '/home/jmads/datasets/momentum/pageview_new_accounts_8-7-22.csv'\n",
    "\n",
    "result_df.to_csv(FILEPATH,index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34f6f113-dcf5-4927-ab70-510667774f53",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
