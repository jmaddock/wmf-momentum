{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "841b2056-dcc8-406c-841d-858c2edf860e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PySpark executors will use /usr/lib/anaconda-wmf/bin/python3.\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python3\n",
    "import wmfdata as wmf\n",
    "import pandas as pd\n",
    "\n",
    "spark = wmf.spark.get_custom_session(\n",
    "    master=\"yarn\",\n",
    "    spark_config={\n",
    "        \"spark.driver.memory\": \"16g\",\n",
    "        \"spark.dynamicAllocation.maxExecutors\": 128,\n",
    "        \"spark.executor.memory\": \"16g\",\n",
    "        \"spark.executor.cores\": 4,\n",
    "        \"spark.sql.shuffle.partitions\": 512\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8777f0c4-f18f-4122-8e79-1c413db20245",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PySpark executors will use /usr/lib/anaconda-wmf/bin/python3.\n",
      "[Stage 33:=====>                                               (28 + 228) / 256]6144]]22/08/23 21:01:55 WARN TaskSetManager: Lost task 40.0 in stage 33.0 (TID 44842, an-worker1094.eqiad.wmnet, executor 368): FetchFailed(BlockManagerId(378, analytics1066.eqiad.wmnet, 7337, None), shuffleId=22, mapId=91, reduceId=40, message=\n",
      "org.apache.spark.shuffle.FetchFailedException: java.util.concurrent.TimeoutException: Timeout waiting for task.\n",
      "\tat org.apache.spark.storage.ShuffleBlockFetcherIterator.throwFetchFailedException(ShuffleBlockFetcherIterator.scala:554)\n",
      "\tat org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:485)\n",
      "\tat org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:64)\n",
      "\tat scala.collection.Iterator$$anon$12.nextCur(Iterator.scala:435)\n",
      "\tat scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:441)\n",
      "\tat scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:409)\n",
      "\tat org.apache.spark.util.CompletionIterator.hasNext(CompletionIterator.scala:31)\n",
      "\tat org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)\n",
      "\tat scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:409)\n",
      "\tat org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage2.agg_doAggregateWithKeys_1$(Unknown Source)\n",
      "\tat org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage2.agg_doAggregateWithKeys_0$(Unknown Source)\n",
      "\tat org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage2.processNext(Unknown Source)\n",
      "\tat org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)\n",
      "\tat org.apache.spark.sql.execution.WholeStageCodegenExec$$anonfun$13$$anon$1.hasNext(WholeStageCodegenExec.scala:636)\n",
      "\tat scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:409)\n",
      "\tat org.apache.spark.shuffle.sort.UnsafeShuffleWriter.write(UnsafeShuffleWriter.java:187)\n",
      "\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:99)\n",
      "\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:55)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:123)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner$$anonfun$10.apply(Executor.scala:408)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1360)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:414)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: java.lang.RuntimeException: java.util.concurrent.TimeoutException: Timeout waiting for task.\n",
      "\tat org.spark_project.guava.base.Throwables.propagate(Throwables.java:160)\n",
      "\tat org.apache.spark.network.client.TransportClient.sendRpcSync(TransportClient.java:263)\n",
      "\tat org.apache.spark.network.crypto.AuthClientBootstrap.doSparkAuth(AuthClientBootstrap.java:105)\n",
      "\tat org.apache.spark.network.crypto.AuthClientBootstrap.doBootstrap(AuthClientBootstrap.java:79)\n",
      "\tat org.apache.spark.network.client.TransportClientFactory.createClient(TransportClientFactory.java:257)\n",
      "\tat org.apache.spark.network.client.TransportClientFactory.createClient(TransportClientFactory.java:187)\n",
      "\tat org.apache.spark.network.shuffle.ExternalShuffleClient.lambda$fetchBlocks$0(ExternalShuffleClient.java:100)\n",
      "\tat org.apache.spark.network.shuffle.RetryingBlockFetcher.fetchAllOutstanding(RetryingBlockFetcher.java:141)\n",
      "\tat org.apache.spark.network.shuffle.RetryingBlockFetcher.start(RetryingBlockFetcher.java:121)\n",
      "\tat org.apache.spark.network.shuffle.ExternalShuffleClient.fetchBlocks(ExternalShuffleClient.java:109)\n",
      "\tat org.apache.spark.storage.ShuffleBlockFetcherIterator.sendRequest(ShuffleBlockFetcherIterator.scala:260)\n",
      "\tat org.apache.spark.storage.ShuffleBlockFetcherIterator.org$apache$spark$storage$ShuffleBlockFetcherIterator$$send$1(ShuffleBlockFetcherIterator.scala:531)\n",
      "\tat org.apache.spark.storage.ShuffleBlockFetcherIterator.fetchUpToMaxBytes(ShuffleBlockFetcherIterator.scala:526)\n",
      "\tat org.apache.spark.storage.ShuffleBlockFetcherIterator.initialize(ShuffleBlockFetcherIterator.scala:365)\n",
      "\tat org.apache.spark.storage.ShuffleBlockFetcherIterator.<init>(ShuffleBlockFetcherIterator.scala:156)\n",
      "\tat org.apache.spark.shuffle.BlockStoreShuffleReader.read(BlockStoreShuffleReader.scala:45)\n",
      "\tat org.apache.spark.sql.execution.ShuffledRowRDD.compute(ShuffledRowRDD.scala:165)\n",
      "\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324)\n",
      "\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:288)\n",
      "\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\n",
      "\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324)\n",
      "\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:288)\n",
      "\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\n",
      "\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324)\n",
      "\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:288)\n",
      "\t... 9 more\n",
      "Caused by: java.util.concurrent.TimeoutException: Timeout waiting for task.\n",
      "\tat org.spark_project.guava.util.concurrent.AbstractFuture$Sync.get(AbstractFuture.java:276)\n",
      "\tat org.spark_project.guava.util.concurrent.AbstractFuture.get(AbstractFuture.java:96)\n",
      "\tat org.apache.spark.network.client.TransportClient.sendRpcSync(TransportClient.java:259)\n",
      "\t... 32 more\n",
      "\n",
      ")\n",
      "[Stage 32:======>        (72 + 4) / 163][Stage 33:=>           (28 + 227) / 256]22/08/23 21:02:25 WARN TaskSetManager: Lost task 163.0 in stage 33.0 (TID 44965, an-worker1094.eqiad.wmnet, executor 368): FetchFailed(BlockManagerId(378, analytics1066.eqiad.wmnet, 7337, None), shuffleId=22, mapId=91, reduceId=163, message=\n",
      "org.apache.spark.shuffle.FetchFailedException: java.util.concurrent.TimeoutException: Timeout waiting for task.\n",
      "\tat org.apache.spark.storage.ShuffleBlockFetcherIterator.throwFetchFailedException(ShuffleBlockFetcherIterator.scala:554)\n",
      "\tat org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:485)\n",
      "\tat org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:64)\n",
      "\tat scala.collection.Iterator$$anon$12.nextCur(Iterator.scala:435)\n",
      "\tat scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:441)\n",
      "\tat scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:409)\n",
      "\tat org.apache.spark.util.CompletionIterator.hasNext(CompletionIterator.scala:31)\n",
      "\tat org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)\n",
      "\tat scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:409)\n",
      "\tat org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage2.agg_doAggregateWithKeys_1$(Unknown Source)\n",
      "\tat org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage2.agg_doAggregateWithKeys_0$(Unknown Source)\n",
      "\tat org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage2.processNext(Unknown Source)\n",
      "\tat org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)\n",
      "\tat org.apache.spark.sql.execution.WholeStageCodegenExec$$anonfun$13$$anon$1.hasNext(WholeStageCodegenExec.scala:636)\n",
      "\tat scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:409)\n",
      "\tat org.apache.spark.shuffle.sort.UnsafeShuffleWriter.write(UnsafeShuffleWriter.java:187)\n",
      "\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:99)\n",
      "\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:55)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:123)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner$$anonfun$10.apply(Executor.scala:408)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1360)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:414)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: java.lang.RuntimeException: java.util.concurrent.TimeoutException: Timeout waiting for task.\n",
      "\tat org.spark_project.guava.base.Throwables.propagate(Throwables.java:160)\n",
      "\tat org.apache.spark.network.client.TransportClient.sendRpcSync(TransportClient.java:263)\n",
      "\tat org.apache.spark.network.crypto.AuthClientBootstrap.doSparkAuth(AuthClientBootstrap.java:105)\n",
      "\tat org.apache.spark.network.crypto.AuthClientBootstrap.doBootstrap(AuthClientBootstrap.java:79)\n",
      "\tat org.apache.spark.network.client.TransportClientFactory.createClient(TransportClientFactory.java:257)\n",
      "\tat org.apache.spark.network.client.TransportClientFactory.createClient(TransportClientFactory.java:187)\n",
      "\tat org.apache.spark.network.shuffle.ExternalShuffleClient.lambda$fetchBlocks$0(ExternalShuffleClient.java:100)\n",
      "\tat org.apache.spark.network.shuffle.RetryingBlockFetcher.fetchAllOutstanding(RetryingBlockFetcher.java:141)\n",
      "\tat org.apache.spark.network.shuffle.RetryingBlockFetcher.start(RetryingBlockFetcher.java:121)\n",
      "\tat org.apache.spark.network.shuffle.ExternalShuffleClient.fetchBlocks(ExternalShuffleClient.java:109)\n",
      "\tat org.apache.spark.storage.ShuffleBlockFetcherIterator.sendRequest(ShuffleBlockFetcherIterator.scala:260)\n",
      "\tat org.apache.spark.storage.ShuffleBlockFetcherIterator.org$apache$spark$storage$ShuffleBlockFetcherIterator$$send$1(ShuffleBlockFetcherIterator.scala:531)\n",
      "\tat org.apache.spark.storage.ShuffleBlockFetcherIterator.fetchUpToMaxBytes(ShuffleBlockFetcherIterator.scala:526)\n",
      "\tat org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:489)\n",
      "\t... 23 more\n",
      "Caused by: java.util.concurrent.TimeoutException: Timeout waiting for task.\n",
      "\tat org.spark_project.guava.util.concurrent.AbstractFuture$Sync.get(AbstractFuture.java:276)\n",
      "\tat org.spark_project.guava.util.concurrent.AbstractFuture.get(AbstractFuture.java:96)\n",
      "\tat org.apache.spark.network.client.TransportClient.sendRpcSync(TransportClient.java:259)\n",
      "\t... 35 more\n",
      "\n",
      ")\n",
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>month</th>\n",
       "      <th>year</th>\n",
       "      <th>wiki_db</th>\n",
       "      <th>num_active_editors</th>\n",
       "      <th>num_bytes_added</th>\n",
       "      <th>num_articles</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9</td>\n",
       "      <td>2004</td>\n",
       "      <td>enwiki</td>\n",
       "      <td>9864</td>\n",
       "      <td>320410731</td>\n",
       "      <td>72187</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9</td>\n",
       "      <td>2004</td>\n",
       "      <td>eswiki</td>\n",
       "      <td>587</td>\n",
       "      <td>16554581</td>\n",
       "      <td>2295</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>2007</td>\n",
       "      <td>viwiki</td>\n",
       "      <td>757</td>\n",
       "      <td>16012165</td>\n",
       "      <td>6400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9</td>\n",
       "      <td>2008</td>\n",
       "      <td>cawiki</td>\n",
       "      <td>1098</td>\n",
       "      <td>29859840</td>\n",
       "      <td>16355</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>2009</td>\n",
       "      <td>cawiki</td>\n",
       "      <td>1594</td>\n",
       "      <td>33984840</td>\n",
       "      <td>21061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3266</th>\n",
       "      <td>10</td>\n",
       "      <td>2014</td>\n",
       "      <td>viwiki</td>\n",
       "      <td>1171</td>\n",
       "      <td>24488060</td>\n",
       "      <td>1091677</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3267</th>\n",
       "      <td>6</td>\n",
       "      <td>2017</td>\n",
       "      <td>bnwiki</td>\n",
       "      <td>486</td>\n",
       "      <td>26183234</td>\n",
       "      <td>61545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3268</th>\n",
       "      <td>7</td>\n",
       "      <td>2017</td>\n",
       "      <td>eswiki</td>\n",
       "      <td>14072</td>\n",
       "      <td>132919273</td>\n",
       "      <td>501030</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3269</th>\n",
       "      <td>12</td>\n",
       "      <td>2019</td>\n",
       "      <td>arwiki</td>\n",
       "      <td>4198</td>\n",
       "      <td>87225529</td>\n",
       "      <td>1064872</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3270</th>\n",
       "      <td>12</td>\n",
       "      <td>2019</td>\n",
       "      <td>idwiki</td>\n",
       "      <td>2913</td>\n",
       "      <td>30516738</td>\n",
       "      <td>305773</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3271 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      month  year wiki_db  num_active_editors  num_bytes_added  num_articles\n",
       "0         9  2004  enwiki                9864        320410731         72187\n",
       "1         9  2004  eswiki                 587         16554581          2295\n",
       "2         4  2007  viwiki                 757         16012165          6400\n",
       "3         9  2008  cawiki                1098         29859840         16355\n",
       "4         1  2009  cawiki                1594         33984840         21061\n",
       "...     ...   ...     ...                 ...              ...           ...\n",
       "3266     10  2014  viwiki                1171         24488060       1091677\n",
       "3267      6  2017  bnwiki                 486         26183234         61545\n",
       "3268      7  2017  eswiki               14072        132919273        501030\n",
       "3269     12  2019  arwiki                4198         87225529       1064872\n",
       "3270     12  2019  idwiki                2913         30516738        305773\n",
       "\n",
       "[3271 rows x 6 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LANGUAGE_EDITIONS = \"('enwiki','eswiki','jawiki','arwiki','dewiki','ptwiki','viwiki','frwiki','cawiki','ruwiki','idwiki','bnwiki','hiwiki','cswiki')\"\n",
    "\n",
    "query = \"\"\"\n",
    "WITH active_editors AS (\n",
    "SELECT\n",
    "    cast(substr(event_timestamp,1,4) as int) as year, \n",
    "    cast(substr(event_timestamp,6,2) as int) as month,\n",
    "    wiki_db,\n",
    "    COUNT(DISTINCT event_user_id) AS num_active_editors\n",
    "FROM wmf.mediawiki_history  \n",
    "WHERE snapshot = '2022-07'\n",
    "AND wiki_db in {0}\n",
    "AND array_contains(event_user_groups,'bot') = FALSE\n",
    "AND revision_is_identity_reverted = FALSE\n",
    "GROUP BY\n",
    "    cast(substr(event_timestamp,1,4) as int),\n",
    "    cast(substr(event_timestamp,6,2) as int),\n",
    "    wiki_db\n",
    "),\n",
    "\n",
    "bytes_added AS (\n",
    "SELECT\n",
    "    cast(substr(event_timestamp ,1,4) as int) as year, \n",
    "    cast(substr(event_timestamp,6,2) as int) as month,\n",
    "    wiki_db,\n",
    "    SUM(revision_text_bytes_diff) AS num_bytes_added\n",
    "FROM wmf.mediawiki_history   \n",
    "WHERE snapshot = '2022-07'\n",
    "AND wiki_db in {0}\n",
    "AND array_contains(event_user_groups,'bot') = FALSE\n",
    "AND revision_is_identity_reverted = FALSE\n",
    "AND revision_text_bytes_diff > 0\n",
    "GROUP BY\n",
    "    cast(substr(event_timestamp,1,4) as int),\n",
    "    cast(substr(event_timestamp,6,2) as int),\n",
    "    wiki_db\n",
    "),\n",
    "\n",
    "articles_created AS (\n",
    "SELECT\n",
    "    cast(substr(start_timestamp ,1,4) as int) as year, \n",
    "    cast(substr(start_timestamp,6,2) as int) as month,\n",
    "    wiki_db,\n",
    "    COUNT(*) AS num_articles_created\n",
    "FROM wmf.mediawiki_page_history \n",
    "WHERE snapshot = '2022-07'\n",
    "AND page_namespace = 1\n",
    "AND wiki_db in {0}\n",
    "GROUP BY\n",
    "    cast(substr(start_timestamp,1,4) as int),\n",
    "    cast(substr(start_timestamp,6,2) as int),\n",
    "    wiki_db\n",
    "),\n",
    "\n",
    "articles_deleted AS (\n",
    "SELECT\n",
    "    cast(substr(end_timestamp ,1,4) as int) as year, \n",
    "    cast(substr(end_timestamp,6,2) as int) as month,\n",
    "    wiki_db,\n",
    "    COUNT(*) AS num_articles_deleted\n",
    "FROM wmf.mediawiki_page_history \n",
    "WHERE snapshot = '2022-07'\n",
    "AND page_namespace = 1\n",
    "AND wiki_db in {0}\n",
    "GROUP BY\n",
    "    cast(substr(end_timestamp,1,4) as int),\n",
    "    cast(substr(end_timestamp,6,2) as int),\n",
    "    wiki_db\n",
    "),\n",
    "\n",
    "num_articles AS (\n",
    "SELECT\n",
    "    articles_created.month,\n",
    "    articles_created.year,\n",
    "    articles_created.wiki_db,\n",
    "    COALESCE(articles_deleted.num_articles_deleted,0) AS articles_deleted,\n",
    "    articles_created.num_articles_created,\n",
    "    articles_created.num_articles_created-COALESCE(articles_deleted.num_articles_deleted,0) AS article_diff,\n",
    "    SUM(articles_created.num_articles_created-COALESCE(articles_deleted.num_articles_deleted,0)) OVER (PARTITION BY articles_created.wiki_db ORDER BY articles_created.year, articles_created.month) AS num_articles \n",
    "FROM articles_created\n",
    "LEFT JOIN articles_deleted\n",
    "ON (articles_created.month = articles_deleted.month AND articles_created.year = articles_deleted.year AND articles_created.wiki_db = articles_deleted.wiki_db)\n",
    "WHERE articles_created.month IS NOT NULL\n",
    "AND articles_created.year IS NOT NULL\n",
    ")\n",
    "\n",
    "SELECT active_editors.month, active_editors.year, active_editors.wiki_db, active_editors.num_active_editors, bytes_added.num_bytes_added, num_articles.num_articles\n",
    "FROM active_editors\n",
    "INNER JOIN bytes_added\n",
    "ON active_editors.year = bytes_added.year AND active_editors.month = bytes_added.month AND active_editors.wiki_db = bytes_added.wiki_db\n",
    "INNER JOIN num_articles\n",
    "ON active_editors.year = num_articles.year AND active_editors.month = num_articles.month AND active_editors.wiki_db = num_articles.wiki_db\n",
    "\"\"\".format(\n",
    "    LANGUAGE_EDITIONS\n",
    ")\n",
    "\n",
    "df = wmf.spark.run(query)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "a1d2a720-f4a4-4c97-8542-0dd5090eaa4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "FILEPATH = '/home/jmads/datasets/momentum/language_edition_first_edit_timestamps_8-23-22.csv'\n",
    "min_age = pd.read_csv(FILEPATH)\n",
    "\n",
    "def getWikiAge(df,min_age_df):\n",
    "    min_age_df = min_age_df.rename(columns={'year':'year_1','month':'month_1'})\n",
    "    df = df.merge(min_age_df, on='wiki_db')\n",
    "    df['wiki_age'] = df['year'].multiply(12).add(df['month']).subtract(df['year_1'].multiply(12).add(df['month_1']))\n",
    "    return df\n",
    "\n",
    "result_df = df.copy()\n",
    "result_df = getWikiAge(result_df,min_age)\n",
    "result_df = result_df.sort_values(['wiki_db','year','month'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "7b5c300f-4a93-4356-8fb0-f9f52adad30d",
   "metadata": {},
   "outputs": [],
   "source": [
    "FILEPATH = '/home/jmads/datasets/momentum/active_editors_content_added_multi-wiki_8-24-22.csv'\n",
    "\n",
    "result_df.to_csv(FILEPATH,index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce5a77f2-c9bc-4fc2-b04f-1219181477f4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
